{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Hassan Mojeed__<br>\n",
    "[Linkedin Profile](https://www.linkedin.com/in/hassanmojeed/)<br>\n",
    "_mojeed.o.hassan@gmail.com_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pricing Perspectives: Research On Long-Term Condo Rentals Across Canada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    " In this project, I will conduct an in-depth analysis of long-term rental pricing in Canada, leveraging the booming real estate market. The primary goal of this project is to uncover patterns related to apartment types, costs, and locations. By deciphering the dynamics that influence housing trends nationwide, this analysis aims to offer valuable insights for both tenants and investors.\n",
    "\n",
    " ### Data Collection\n",
    "\n",
    " The data used in this project was scraped from Kijiji, a well-known Canada's leading local classifieds platform, facilitating the buying, selling, and trading of a wide range of items, including cars, real estate, jobs, services, and more. It operates as a subsidiary of eBay and has a significant presence in Canada, as well as in other countries like Switzerland, Austria, and Japan. \n",
    " \n",
    " I will be performing some activities such as;\n",
    "\n",
    "- Looping: to iteratively navigate through pages, and\n",
    "- Extracting vital information such as:\n",
    "\n",
    "    1. Apartment type\n",
    "    2. Rental cost\n",
    "    3. Location\n",
    "    4. Description\n",
    "    5. Number of rooms. \n",
    "To efficiently parse the HTML content, I will use the BeautifulSoup library.\n",
    "\n",
    "### Data Processing\n",
    "The data processing and cleaning procedures in the involve employing diverse techniques. To extract attribute-based text, a custom function called extract_text is utilized, while specific HTML tags are employed to target relevant information.\n",
    "\n",
    "### Data Export\n",
    "The data is transformed into a Pandas DataFrame after undergoing a cleaning process. Subsequently, the final DataFrame is exported to an Google sheet file in order to facilitate further analysis. This step guarantees a consistent and easily accessible format for subsequent stages.\n",
    "\n",
    "### Data Visualization\n",
    "Utilizing Power BI, the exported data is transformed into visually appealing dashboards and impactful visual representations of key metrics. By harnessing the capabilities of Power BI, stakeholders gain a holistic view of rental patterns, facilitating informed decision-making in the ever-evolving real estate market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from bs4 import BeautifulSoup  # BeautifulSoup is used for web scraping\n",
    "import requests  # Used for making HTTP requests\n",
    "import pandas as pd  # Pandas library for data manipulation and analysis\n",
    "import numpy as np\n",
    "from df2gspread import df2gspread as d2g\n",
    "import os\n",
    "from glob import glob\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_numbers = np.arange(1,25)\n",
    "\n",
    "# Initialize an empty list to store apartment rental details\n",
    "apartment_rental_details = []\n",
    "\n",
    "\n",
    "# Loop through the pages\n",
    "for page_number in page_numbers:\n",
    "\n",
    "    # Define the base URL for Kijiji apartment listings\n",
    "    base_url = \"https://www.kijiji.ca/b-apartments-condos/canada/page-\"\n",
    "\n",
    "    # URL separator for sorting by date in descending order\n",
    "    url_separator = \"/c37l0\"\n",
    "\n",
    "    # Construct the full URL for the current page\n",
    "    url = base_url + str(page_number) + url_separator\n",
    "\n",
    "    # Make an HTTP GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    page = BeautifulSoup(response.text, \"html\")\n",
    "\n",
    "    # Find the container holding the apartment listings\n",
    "    listings = page.find_all(\"ul\", class_=\"sc-608fbfb8-0 hZVmEd\")[1]\n",
    "\n",
    "    # Find all individual apartment sections within the container\n",
    "    apartments = listings.find_all(\"div\", {\"class\" : \"sc-388271ae-4 gLeCuw\"})\n",
    "\n",
    "    # Loop through each apartment section\n",
    "    for apartment in apartments:\n",
    "\n",
    "        # Define a function to extract text from specific HTML elements\n",
    "        def extract_text(attribute1, attribute2):\n",
    "            try:\n",
    "                return apartment.find(attribute1, attribute2).text.replace(\",\", \"\")\n",
    "            except AttributeError:\n",
    "                return None\n",
    "\n",
    "        def extract_desc(attribute1, attribute2):\n",
    "            try:\n",
    "                return apartment.find(attribute1, attribute2).text\n",
    "            except AttributeError:\n",
    "                return None\n",
    "    \n",
    "        # Extract apartment details: type, rental cost, location, and description\n",
    "        apartment_type = apartment.find(\"h3\", class_=\"sc-c54bbc09-0 KhHgs sc-388271ae-7 jJiZEd\").text\n",
    "        rental_cost = extract_text(\"div\", {\"class\": \"sc-c12cb283-0 lokBaA\"})\n",
    "        location = apartment.find(\"div\", class_=\"sc-76274460-0 hKNTpz\").text\n",
    "        description = extract_desc(\"p\", {\"class\" : \"sc-c54bbc09-0 loTzYZ sc-388271ae-8 fzjNiw\"})\n",
    "\n",
    "        # Append the apartment details to the list\n",
    "        apartment_rental_details.append([apartment_type, rental_cost, location, description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas DataFrame using the apartment_rental_details list\n",
    "# Specify column names as \"Apartment_type\", \"Rental_cost\", \"Location\", and \"Description\"\n",
    "df = pd.DataFrame(apartment_rental_details, columns=[\"Apartment_type\", \"Rental_cost\", \"Location\", \"Description\"])\n",
    "\n",
    "# Filter rows in the DataFrame where \"Rental_cost\" is not equal to \"please Contact\"\n",
    "df = df[df[\"Rental_cost\"] != \"Please Contact\"].dropna()\n",
    "\n",
    "# Reset the index of the DataFrame and create a new DataFrame 'data'\n",
    "df1 = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g8/_pf9ppwx4k9c3x4m_c_hvx640000gn/T/ipykernel_5892/2486160606.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"Rental_cost\"] = [x.strip(\"$\") for x in data[\"Rental_cost\"]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Apartment_type    0\n",
       "Rental_cost       0\n",
       "Location          0\n",
       "Description       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= df1.drop_duplicates()\n",
    "data[\"Rental_cost\"] = [x.strip(\"$\") for x in data[\"Rental_cost\"]]\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mj/Projects/Projects/webscrapingProject/cool-ship-407420-9aadad67f295.json'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "file = path + '/cool-ship-407420-9aadad67f295.json'\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mj/Projects/Projects/webscrapingProject/lib/python3.11/site-packages/df2gspread/df2gspread.py:138: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sheet is uploaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive', 'https://www.googleapis.com/auth/drive.file', 'https://www.googleapis.com/auth/spreadsheets']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(file, scope)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# Create a new Google Sheets file with the name 'Rental Price Perspective'\n",
    "spreadsheet = client.create('Rental Price Perspective')\n",
    "\n",
    "# Specify the spreadsheet key for the newly created Google Sheets file\n",
    "spreadsheet_key = '1ixobCbTWoQAJ-vXYOuu3ruvcULtWtKlhIQXoTQpUk_8'\n",
    "\n",
    "# Uncomment the following lines if you want to work with the default first sheet\n",
    "# Get the default first sheet\n",
    "# sheet = spreadsheet.sheet1\n",
    "\n",
    "# Update the Google Sheets with the DataFrame\n",
    "# sheet.update([data.columns.values.tolist()] + data.values.tolist())\n",
    "\n",
    "# Define the worksheet name and starting cell for the data upload\n",
    "worksheetName = 'Sheet1'\n",
    "starting_cell = 'A1'\n",
    "\n",
    "# Upload the data to Google Sheets using the d2g library\n",
    "d2g.upload(data, spreadsheet_key, worksheetName, credentials=creds, col_names=True, row_names=False, start_cell=starting_cell, clean=False)\n",
    "\n",
    "# Print a success message\n",
    "print('The sheet is uploaded successfully')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Click here for the dynamic visuals](https://app.powerbi.com/view?r=eyJrIjoiOWFmNzQ0ODgtM2IzYy00NGFkLTk1YzMtOWUwMzQzM2Q1YjAzIiwidCI6ImFlM2E5OTA2LTc4MWEtNDQ2YS1iZGI2LTYzNzdjMDllMmM2ZiIsImMiOjF9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Click here for scraped data](https://docs.google.com/spreadsheets/d/e/2PACX-1vStFRr--ayUoUfnB2MR6WeUFwjyzAJtNX0jyuBIw-y0DOPMHDt48HBIsz9DEwK2gV_oXsuLkdL2PI1b/pubhtml)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
